\documentclass{article}

\usepackage{amsmath,amsfonts,amsthm,amssymb,amsbsy,amstext,amscd,amsxtra,multicol,mathtools}
\usepackage{mathtext}

\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{textcomp}
\usepackage{graphicx}
\graphicspath{ {./images/} }
\usepackage{float}
\usepackage{color}
% \usepackage{xspace}
% \usepackage[document]{ragged2e}
% \usepackage{multirow}
\usepackage{indentfirst}
% \usepackage{verbatim}
\usepackage{tikz}
% \usepackage{forest}

% Объединение ячеек
\usepackage{adjustbox}
\usepackage{multirow}

% Выделенное поле для примечаний
\usepackage[most]{tcolorbox}
\definecolor{block-gray}{gray}{0.90} % уровень прозрачности (1 - максимум)
\newtcolorbox{myquote}{colback=block-gray, grow to right by=0mm, grow to left by=0mm,
boxrule=0pt,boxsep=0pt,breakable} % настройки области с изменённым фоном

\setlength{\parindent}{0.8cm}
\setlength{\parskip}{0cm}

\def\eps{\varepsilon}
\usepackage[left =2cm, right=2cm, top=2cm, bottom=2cm, bindingoffset=0cm]{geometry}

% Настройка секций (внутрення нумерация, номер не отображается)
\renewcommand{\thesection}{}
\renewcommand{\thesubsection}{\arabic{section}.\arabic{subsection}}
\makeatletter
\def\@seccntformat#1{\csname #1ignore\expandafter\endcsname\csname the#1\endcsname\quad}
\let\sectionignore\@gobbletwo
\let\latex@numberline\numberline
\def\numberline#1{\if\relax#1\relax\else\latex@numberline{#1}\fi}
\makeatother

% Нумерация уравнений
\numberwithin{equation}{subsection}

\usepackage{hyperref}% http://ctan.org/pkg/hyperref
\hypersetup{%
  colorlinks = true,
  linkcolor  = black
}





\begin{document}

\author{Лабунец Л.В. \& Паймин Антон}
\title{Нейронные сети. Лекции.}

\makeatletter
\begin{center}
    {\fontsize{14pt}{24pt}\selectfont\bfseries\@title\par}
    {\fontsize{14pt}{16pt}\@author\par}
\end{center}
\makeatother

\tableofcontents
\newpage

% \setcounter{section}{4}
\section{Лекция}

\subsection{Математическая модель многослойного перцептрона}

Рассмотрим на примере 3-слойной архитектуры (в количество слоёв входят только 
слои, реализующие нелинейное отображение).
Рассмотрим сигналы, поступающие на вход нейронов, но для избежания 
путаницы, будем визуализировать связи только для первых нейронов соответствующих слоёв.
Рассмотрим эти связи и соотв. им параметры.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{hyperflat_3_1.jpeg}
    \caption{Структура многослойного перцептрона}
    \label{hyperflat_3_1}
\end{figure}

3-слойный перцептрон содержит 0-й слой - слой источников (черные квадратики). 
Имеется $m_{0}$ входов, на которые поступают признаки 
$\vec{x} = (1, x_0, ..., x_{m_{0}})$, 3 скрытых слоя.

Примем следующие правила индексации скрытых нейронов и нейронов выходного слоя:
первый эл-т индекса - номер нейрона, второй - номер слоя: 
$m_{i,j}$  - $i$-й нейрон $j$-го скрытого слоя.

Выпишем веса нейронов $i$-го слоя в виде матрицы $W_i$, столбец которой 
$\vec{w}_i^{(k)}$ является вектором весов $i$-го нейрона $k$-го слоя.
Количество строк матрицы - количество входов слоя \glqq +1\grqq 
(на вход поступает расширенный вектор), количество столбцов - количество нейронов слоя.
Элемент матрицы $w_{i,j}^{(k)}$ - вес $i$-го входа $j$-го нейрона $k$-го слоя.
У первого скрытого слоя имеется $m_0$ входов (слой источников) 
и он содержит $m_1$ нейронов.

\begin{equation}
    W_1 = 
    \begin{pmatrix}
        w_{0,1}^{(1)} & w_{0,2}^{(1)} & \dots & w_{0,{m_1}}^{(1)} \\
        w_{1,1}^{(1)} & w_{1,2}^{(1)} & \dots & w_{1,{m_1}}^{(1)} \\
        w_{2,1}^{(1)} & w_{2,2}^{(1)} & \dots & w_{2,{m_1}}^{(1)} \\
        \vdots        & \vdots        & \ddots & \vdots           \\
        w_{{m_0},1}^{(1)} & w_{{m_0},2}^{(1)} & \dots & w_{{m_0},{m_1}}^{(1)} \\
    \end{pmatrix}
\end{equation}

Рассмотрим первый слой.
На вход каждого нейрона слоя поступает сигнал смещения $+1$, взвешиваемый 
\textit{биасом} $w_{0,i}^{(1)}$. 
Также на вход этого нейрона поступают входные признаки $x_i$, взвешиваемые 
\textit{синаптическими весами} $w_{1,j}^{(1)}$ до $w_{{m_0},j}^{(1)}$ - веса $i$-го признака $j$-го нейрона в первом слое.   
Для экономии места введём вектор синаптических весов конкретного нейрона:

\begin{equation}
    \vec{w}_j^{(k)} = 
    \begin{pmatrix}
        w_{0,j}^{(k)} & w_{1,j}^{(k)} & \dots & w_{{m_0},j}^{(k)}
    \end{pmatrix}
    ^T
\end{equation}


Индекс в скобках - номер слоя, нижний индекс - номер нейрона. Т.е., $\vec{w}_1^{(1)}$ - вектор синаптических весов 1-го нейрона 1-го слоя.

На выходе $i$-го нейрона $k$-го слоя формируется сигнал $u_i^{(k)}$. 
Выпишем формулу для вычисления сигнала на выходе 1-го нейрона 1-го слоя $u_1^{(1)}$. Опять, в скобках - номер слоя, индекс - номер нейрона.
Для этого необходимо посчитать сигнал на выходе сумматора $k$-го нейрона (\textit{индуцированного локального поля}):

\begin{myquote}
    \textit{Не очень удачно были выбраны индексы, но оставил, как на презентации}
\end{myquote}

\begin{equation}
    {v}_k^{(1)} = \sum_{j=0}^{m_0} w_{j,k}^{(1)} \cdot x_j = [\vec{w}_{k}^{(1)}]^T \cdot \vec{x}
\end{equation}


\begin{equation*}
    {v}_2^{(1)} = [\vec{w}_{2}^{(1)}]^T \cdot \vec{x}
\end{equation*}

где $j$ - номер нейрона, $k$ - номер слоя, $w_{j,k}^{(1)}$ - компоненты ..., $\vec{x}$ ---
 расширенный вектор.

Из приведённых выражений можем получить общее: $W_k^T \cdot \vec{x}$ --- совокупность элементов 
на выходе сумматоров всех нейронов $k$-го слоя.

Полученные на выходе сумматора значения подвергаются нелинейному преобразованию 
с помощью функции активации $\varphi(W_k^T \cdot \vec{x})$. Получаем совокупность 
сигналов на выходе функций активации нейронов. 
Для первого слоя: $\varphi(W_1^T \cdot \vec{x})$, для второго: $\varphi(W_2^T \cdot \vec{x})$ и т.д.

Для получения из матрицы $W_1$ матрицы $W_2$ рисуем таблицу:

\begin{center}
    Количество входов и выходов скрытых слоёв (без учёта "расширенности" векторов):

    \begin{tabular}{c | c |  c | c |}
        & 1 слой & 2 слой & 3 слой \\
        \hline
        Количество входов  & $m_0$ & $m_1$ & $m_2$ \\
        \hline
        Количество выходов & $m_1$ & $m_2$ & $m_3$ \\
        \hline
    \end{tabular}
\end{center}

Выпишем матрицу $W_2$;
\begin{equation}
    W_2 = 
    \begin{pmatrix}
        w_{0,1}^{(2)} & w_{0,2}^{(2)} & \dots & w_{0,{m_2}}^{(2)} \\
        w_{1,1}^{(2)} & w_{1,2}^{(2)} & \dots & w_{1,{m_2}}^{(2)} \\
        w_{2,1}^{(2)} & w_{2,2}^{(2)} & \dots & w_{2,{m_2}}^{(2)} \\
        \vdots        & \vdots        & \ddots & \vdots           \\
        w_{{m_1},1}^{(2)} & w_{{m_1},2}^{(2)} & \dots & w_{{m_1},{m_2}}^{(2)} \\
    \end{pmatrix}
\end{equation}

И получим выходы сумматоров нейронов второго слоя:

\begin{myquote}
    Починить расширенные вектора!
\end{myquote}

\begin{equation}
    \vec{u}_2 = W_2^T \cdot [\dfrac{1}{\varphi(W_1^T \cdot \vec{x})}]
\end{equation}


В формуле 1 в якобы числителе - добавленный первый элемент, чтобы получить расширенный вектор-столбец.

\begin{equation}
    \vec{u}_3 = \varphi(W_3^T[\dfrac{1}{\varphi(W_2^T \cdot [\dfrac{1}{\varphi(W_1^T \cdot \vec{x})}])}])
\end{equation}

Для 4-го слоя получим:

\begin{myquote}
    \textit{Выписать матрицу с рисунка для 4 слоя, поправить формулу и выписать её}
\end{myquote}

Увеличение слоёв нецелесообразно из-за рекурсивной структуры модели многослойного 
перцептрона (последовательность вложенных блоков), что приводит к уменьшению 
скорости вычисления, увеличению занимаемой памяти и накопления ошибок.
Также по мере увеличения параметров модели, возникает \textit{эффект переобучения}, 
а по мере увеличения количества слоёв количество параметров увеличивается экспоненциально.

Возможно применение альтернативных архитектур - например, сети радиальных базисных функций.
Также необходимо применение методов регуляризации, например, метод \textit{хирургии мозга} ---
исключения из каждого слоя неинформативных нейронов или целых слоёв.
Существуют методы обучения, подразумевающие цикличность.

\begin{myquote}
    \textit{Более детально см. "Нейронные сети. Полный курс" Саймона Хайкина.}
\end{myquote}

Также существует теорема, доказанная Колмогоровым, утверждающая, что многомерная 
скалярная функция может воспроизводить любую закономерность сколь угодно большой 
сложности. Теорема об универсальной аппроксимации многослойным перцептроном 
утверждает, что архитектура многослойного перцептрона \textit{теоретически} 
позволяет с любой заданной точностью синтезировать многомерную по количеству 
входов векторную функцию, что позволяет строить модели нелинейных 
дискриминантных границ в пространстве признаков и, соответственно, определять 
принадлежность данных кластерам. 




\subsection{Системный подход к синтезу алгоритмов обучения многослойного перцептрона}

Согласно системному подходу к синтезу алгоритмов обучения многослойного перцептрона, 
необходимо выполнить 3 шага:
\begin{enumerate}
    \item Выбор цели обучения;
    \item Оценка градиента средних потерь целевой функции по параметрам нейронной сети;
    \item Использование алгоритмом поиска оптимальных параметров.
\end{enumerate}

Предполагается наличие функционала качества работы системы, оптимальное значение 
которого и ищется.

\begin{figure}[htbp]
    \centering
    \includegraphics[height=8 cm]{hyperflat_4_1.jpeg}
    \caption{Обучение нейронной сети}
    \label{hyperflat_4_1}
\end{figure}

Будем рассматривать 3 объекта анализа
\begin{enumerate}
    \item Пространство входных воздействий $\vec{x}$ - сигналы, поступающие на вход системы 
    (обучающие и контрольные примеры), и соответствующее пространство входных воздействий, 
    в котором существует область $D$ все возможных входных воздействий;
    \item Вектор параметров системы $\vec{C}$ и пространство, ему соответствующее, 
    в которому существуют эквипотенциальные гиперповерхности, все точки которых 
    соотв. определенным значениям функционала качества. Необходимо найти 
    область минимальных/максимальных значений этого функционала качества;
    \item Функция стоимости (потерь, приобретений) $Q(\vec{x}, \vec{c})$, 
    определяющая потери/приобретения, которые можно измерить, если на вход 
    системы поступает воздействие $\vec{x}$, а система находится в в состоянии $\vec{C}$.
\end{enumerate}

Набор этих 3 объектов позволяет математически строго сформулировать выбор цели обучения 
в виде функционала средних потерь (среднего риска).
Сделать это несложно, необходимо протестировать область $D$ всех входных воздействий: 
зафиксировать $\vec{x}$ и выбрать параметры системы $\vec{C}$. 

Для каждого зафиксированного выбора параметров системы необходимо вычислить 
потери по выбранной для каждого входного воздействия и просуммировать их:

\begin{equation}
    J(\vec{C}) = \int_{D} Q(\vec{x}, \vec{C}) p(\vec{x}) d\vec{x}
    \label{eq:avg_risk}
\end{equation}

Полученное $J(\vec{C})$ - \textit{средний риск} (\textit{средние потери}), $p(\vec{x})$ --- 
весовая функция, сглаживающая аномальные значения (плотность распределения вероятностей 
входных воздействий).

На практике возможны 2 ситуации:
\begin{enumerate}
    \item Нетипичный случай полной априорной определённости - полное знание входных 
    воздействий (весовой функции $p(\vec{x})$, Типа распределения и тд.);
    \item Типичный случай - функция задана набором обучающий примеров
\end{enumerate}

Во втором случае необходимо выполнить предварительную выборочную оценку весовой функции 
$p(\vec{x})$ по набору обучающих примеров.

Однако, будем считать весовую функцию $p(\vec{x})$ известной, тогда возможно посчитать функционал 
ошибок $J(\vec{C})$.

\subsection{Алгоритм обучения нейронной сети (метод градиентного поиска)}
\begin{enumerate}
    \item Выбрать начальное приближение параметров нейронной сети $\vec{C}[0]$ 
    ($0$ - номер итерации), и оценить потери;
    \item Выбрать оптимальное направление поиска (вектор антиградиента 
    $-\nabla\vec{C}$, указывающий направление, в котором потери убывают 
    с максимальной скоростью);
    \item Выбрать шаг поиска (используется процедура стохастической 
    аппроксимации Роббенса-Монро, в соответствии с которой с каждой 
    итерацией длина шага уменьшается обратно пропорционально номеру итерации);
    \item[] В полученной точке выполняется подтверждение сходимости 
    (сравнение итераций), вычисление нового направления и шага.
    \label{en:alg}
\end{enumerate}

Процедура описывается следующим выражением:

\begin{equation}
    \vec{C}[i] = \vec{C}[i-1] - \Gamma[i] \nabla\vec{C} \{ J(\vec{C}[i-1]) \}
\end{equation}

Здесь $\Gamma[i]$ --- матрица усиления, управляющая выбором величины шага поиска.
Если она является диагональной, то по каждому признаку шаги будут независимы 
(характерно для случая гиперсфероидальной топологии гиперповерхностей равных
значений функции стоимости).

Цель обучения: 

\begin{equation}
    \vec{C}_{opt} = \arg \min_{\vec{C}} \{ J(\vec{C}) \}
\end{equation}

Существуют также методы, не требующие вычисления частной производной, ---
 метод деформируемого многогранника Нелдера-Мида (симплекс-поиск).

\begin{myquote}
    \textit{Прикладное нелинейное программирование, Химмельблау}
\end{myquote}

Обучение сводится к решению задачи оптимизации. Существуют ограничения на значения параметров 
системы в виде равенств или неравенств.

Результаты выполнения алгоритма зависят от выбора начального приближения, что приводит 
к необходимости выбора нескольких начальных приближений для обнаружения всех локальных 
минимумов. Существенное преимущество в этом случае обеспечивают генетические алгоритмы.




\section{Лекция 04.09 (дистанционная)}

\subsection{Алгоритм обучения нейронной сети для случая набора обучающих примеров}

\begin{figure}[htbp]
    \centering
    \includegraphics[height=10 cm]{hyperflat_5_1.jpeg}
    \caption{Системный подход к обучению многослойного перцептрона}
    \label{hyperflat_5_1}
\end{figure}

В подавляющем большинстве практических приложений весовая функция $p(\vec{x})$, 
входящая в выражение функционала среднего риска \ref{eq:avg_risk} задана неявным 
образом в виде набора обучающих примеров $\hat{p}(\vec{x})$.

Здесь и далее обучающие примеры, ранее обозначавшиеся $\vec{x}$, будем обозначать
$\vec{X}$. Объём выборки - $N$ обучающих примеров (см. левый столбец 
на \ref{hyperflat_5_1}), размерность пространства признаков $\{ x_1, \dots, x_n \}$ ---
$n$.

Таким образом в $x$-пространстве имеется набор обучающих примеров 
$\vec{X}[1],\dots,\vec{X}[N]$, визуализированных диаграммой рассеяния 
(график на \ref{hyperflat_5_1}). Точка задаётся радиус-вектором, набор которых
задаёт набор обучающих примеров.

Для приближения функционала среднего риска к реальности, дополним его ещё одной осью 
$\hat{p}(\vec{x})$, вдоль которой будем откладывать значения оценки весовой функции, 
где $\Hat{\textup{крышечка}}$ показывает, что это оценка.

В теории искусственного интеллекта существует огромное количество непараметрических,
параметрических и полупараметрических описаний распределений,
в т.ч. и вероятностных. Например, примером параметрического описания многомерного
распределения является модель конечной смеси стандартных распределений, для идентификации
параметров которой служат EM-алгоритмы.
Пример полупараметрической оценки --- ядерная оценка Парзена-Розенблатта,
одномерная модель ПРВ в виде гистограммы, сглаженной сдвигом (с обобщением
до многомерной модели).

\begin{myquote}
    \textit{Ссылка на книгу David Scott, Multivariate Density Estimation}
\end{myquote}




\subsubsection{Ядерная модель Парзена-Розенблатта}

Идея заключается в ассоциировании функции ядра каждой точкой в подпространстве 
признаков с каждым наблюдением (обучающим примером) --- \glqq гиперхолмы\grqq 
на рисунке \ref{hyperflat_5_1}.
Рассмотрим простейший случай, когда оценка обладает единственным параметром 
сглаживания для всех наблюдений --- \textit{неадаптивная ядерная оценка Парзена-
Розенблатта}.

Такие функции обладают важными свойствами.
Гиперобъём под поверхностью функции ядра всегда равен 1 (функция ядра интегрируема с 1).
Также, как и у любой оценки многомерного ПРВ, присутствует параметр сглаживания
(в одномерном случае --- ширина разрядного интервала,
в многомерном случае -- гиперобъём гиперпараллелепипеда), регулирующий степень 
убывания высоты холма по мере удаления текущего радиса-вектора (аргумента ПРВ)
от центра холма (выбранного обучающего примера). 

Если текущее значение совпадает с выбранным примером, то высота максимальна. 
По мере удаления от \textit{центра опорной области} (центра холма) высота асимптотически
стремится к $0$. Аналогично случаю гистограммной оценки, при стремлении параметра 
сглаживания к 0 (масштаб функции ядра нулевой) высота будет неограниченно возрастать,
а опорная область асимптотически стягиваться к 0 и приближаться к дельта-функции 
Дирака --- набору \glqq иголок\grqq единичного объёма в гиперпространстве.
Такие \glqq иголки\grqq не могут иметь общие области и, таким образом, 
ядерная оценка при таком выборе параметров превращается в \glqq лес иголок\grqq 
и (что плохо) сглаживание экспериментальных производится не будет
 --- \textit{эмпирическая оценка весовой функции}.

\begin{equation}
    \hat{p}(\vec{x}) = \dfrac{1}{N} \sum_{k=1}^{N} \delta(\vec{x} - \vec{X}[k])
    \label{eq:empirical_weight_func}
\end{equation}

Для эмпирической оценки суммируем дельта-функции, ассоциированные с обучающими примерами
и масштабируем значение в зависимости от числа обучающих примеров.

\begin{myquote}
    \textit{Обещано позже положительное свойство}
\end{myquote}

В ядерной оценке Парзена-Розенблатта увеличивается параметр сглаживания и опорная область
расширяется по мере увеличения параметра сглаживания, а высота \glqq холмов\grqq
начинает уменьшаться и ближайшие обучающие примеры начинают перекрываться, происходит
постепенное сглаживание совокупности обучающих примеров и получаем \glqq гиперрельеф\grqq.

До некоторого момента при определённом числовом диапазоне параметров 
сглаживания гиперрельеф сохраняет свою морфологию --- наблюдается определённое количество
вершин, что свидетельствует о наличии кластерной структуры в данных и характеризует
статистическую устойчивость оценки ПРВ при выборе параметра сглаживания из этого диапазона.

При дальнейшем увеличении параметра сглаживания опорные области функций-ядер начинают
чрезмерно увеличивать и кластерная структура гиперрельефа начинает
исчезать и в асимптотике стремится к плато --- равномерному распределению 
по всем признакам.

Существует набор методов, позволяющих выбрать оптимальное значение параметров сглаживания,
который позволяет обнаружить кластерную структуру, т.е. \textit{многомодовый характер} 
гиперрельефа в $n$-мерном пространстве признаков.

Один из таких методов - \textit{метод скользящей проверки} выбора оптимального параметра
сглаживания. Существуют также адаптивные ядерные оценки, в которых для каждого наблюдения
выбирается свой оптимальный параметр сглаживания и каждый \glqq гиперхолм\grqq будет
обладать своей оптимальной опорной областью (похоже на выбор характеристик масштаба 
модели конечной смеси стандартных распределений).
В ещё более сложных оценках индивидуальными являются не только параметры сглаживания,
но и модель функция ядра, например, \textit{адаптивная фильтрационная ядерная оценка
плотности распределения вероятности}. Это отдельное направление, связанное с 
построением оптимальных оценок одномерных ПРВ.

\begin{myquote}
    \textit{Есть статья на labnet.ru - Рандомизация многомерных распределений в метрике
    Махаланобиса}
\end{myquote}




\subsubsection{Интегрирование весовой функции среднего риска в конечном виде}

Конечная цель --- получить возможность проинтегрировать \ref{eq:avg_risk} в конечном 
виде, чтобы получить в конечном виде оценку среднего риска, поскольку
необходимо сформировать оценки компонентов вектора градиента и реализовать этот 
алгоритм обучения для практических приложений. 

В этом случае поможет эмпирическая оценка --- плата за попытку 
получить выражение \ref{eq:avg_risk} является грубая эмпирическая 
оценка весовой функции, которая преднамеренно игнорирует процедуру
сглаживания обучающих данных.

Преимущество --- фильтрующее свойство дельта-функции. При подстановке \ref{eq:empirical_weight_func}
в \ref{eq:avg_risk}:

\begin{equation}
    \hat{J}(\vec{C}) = \int_{D} Q(\vec{x}, \vec{C}) \hat{p}(\vec{x}) d\vec{x}
    = \dfrac{1}{N} \int_{D} Q(\vec{x}, \vec{C}) \sum_{k=1}^{N} \delta(\vec{x} - 
    \vec{X}[k]) d\vec{x}
\end{equation}

\noindent
при смене порядка суммирования и интегрирования дельта-функция \glqq профильтрует \grqq
значения весовой функции для каждого обучающего примера:

\begin{equation}
    \hat{J}(\vec{C}) = \dfrac{1}{N} \sum_{k=1}^{N} \int_{D} 
    Q(\vec{x}, \vec{C}) \cdot \delta(\vec{x} - \vec{X}[k]) d\vec{x}
\end{equation}

Произведение функции стоимости и дельта-функции, ассоциированной с конкретным обучающим
примером $Q(\vec{x}, \vec{C}) \cdot \delta(\vec{x} - \vec{X}[k])$ даст значение функции
стоимости для конкретного обучающего примера.

Таким образом, эмпирическая оценка функционала среднего риска представляет собой сумму
функции стоимости по всем обучающим примерам для выбранного вектора параметров системы,
нормированную по количеству обучающих примеров, т.е. выборочное среднее мат. ожидания
функции стоимости:

\begin{equation}
    \hat{J}(\vec{C}) = \dfrac{1}{N} \sum_{k=1}^{N} Q(\vec{X}[k], \vec{C})
\end{equation}

Применение выборочного среднего означает неробастность функции, т.е. неустойчивость
к аномалиям. Финальный алгоритм обучения будет обладать значимой шумовой компонентой 
и игнорирование влияния аномалий тоже скажется на качестве текущих оценок параметров 
обучения системы в процессе их настройки.

Поскольку вектор градиента есть набор частных производных, а операции суммирования 
и дифференцирования перестановочны, то запишем выражение для эмпирической оценки вектора
градиента:

\begin{equation}
    \nabla_{\vec{C}} {\hat{J}(\vec{C})} = \dfrac{1}{N} \sum_{k=1}^{N} \nabla_{\vec{C}}{Q(\vec{X}[k], \vec{C})}
\end{equation}




\subsubsection{Пакетный, последовательный и комбинированный режимы обучения}

Подставим полученную в конечном виде оценку градиента в синтезированный ранее алгоритм,
получим адаптированный к случаю обучения системы по набору параметров алгоритм:

\begin{equation}
    \vec{C}[i] = \vec{C}[i-1] - \Gamma[i] \sum_{k=1}^{N} \nabla\vec{C} \{ Q(\vec{X}[k], \vec{C}[i-1]) \}
\end{equation}

Пока операцию суммирования (усреднения по всем возможным значения компонент вектора 
градиента) сохраняем.

Проанализируем обучение системы при наличии этого усреднения. В этом случае процедура 
обучения реализует \textit{пакетный режим} обучения (см. \ref{table:packet_training}).

В распоряжении имеется набор из $N$ обучающих примеров, происходит инициализация алгоритма
обучения начальными значениями параметров системы. Прежде чем откорректировать начальное
приближение параметров системы в соответствии с существованием этой суммы, необходимо
перебрать все обучающие примеры, вычислить значения функции стоимости и частные 
производные для всех обучающих примеров, получить в $C$-пространстве набор направлений
оптимальных поисков (свой для каждого примера), просуммировать эти вектора, взять 
усреднённое направление поиска с отрицательным знаком, гарантирующее приемлемую скорость
убывания, выбрать величину шага и только после этого от $\vec{C}[0]$ перейти к $\vec{C}[1]$.
На следующей итерации шаги повторяются.

Пакетный режим обучения требует максимально возможной памяти.

\begin{table}[htbp]
    \centering
    \caption{Описание пакетного режима обучения}
    \label{table:packet_training}
    \begin{tabular}{c | c | c}
        Вектор параметров системы     & $i$ --- Номер итерации обучения & $k$ --- Номер обучающего примера \\\hline
        \multirow{3}{*}{$\vec{C}[0]$} & \multirow{3}{*}{1}  & 1 \\\cline{3-3}
                                      &                     & $\vdots$\\\cline{3-3}
                                      &                     & $N$ \\\hline
        \multirow{3}{*}{$\vec{C}[1]$} & \multirow{3}{*}{2}  & 1 \\\cline{3-3}
                                      &                     & $\vdots$\\\cline{3-3}
                                      &                     & $N$ \\\hline
        $\vdots$                      & $\vdots$            & $\vdots$ \\\hline
    \end{tabular}
\end{table}

Альтернативой пакетному режиму обучения является \textit{последовательный режим обучения}
(см. \ref{table:seq_training}).
Для этого опускаем операцию суммирования всех возможных направлений и после каждого
обучающего примера выполняем коррекцию:

\begin{equation}
    \vec{C}[i] = \vec{C}[i-1] - \Gamma[i] \nabla\vec{C} \{ Q(\vec{X}[k], \vec{C}[i-1]) \}
\end{equation}

при последовательном режиме обучения эффект шумовой компоненты существенно 
усиливается, поэтому на практике выбирают \glqq золотую середину\grqq, что
согласуется с процедурами сглаживания временных рядов.

\begin{table}[htbp]
    \centering
    \caption{Описание последовательного режима обучения}
    \label{table:seq_training}
    \begin{tabular}{c | c | c}
        Вектор параметров системы     & $i$ --- Номер итерации обучения & $k$ --- Номер обучающего примера \\\hline
        $\vec{C}[0]$                  & 1                   & 1 \\\hline
        $\vec{C}[1]$                  & 2                   & 2 \\\hline
        $\vdots$                      & $\vdots$            & $\vdots$\\\hline
        $\vec{C}[N]$                  & N                   & N \\\hline
    \end{tabular}
\end{table}

Выберем некоторую компоненту в параметрах системы --- временной ряд в терминологии
номера итерации обучения. Этот ВР будет иметь интересующую трендовую составляющую,
шумовою и, возможно, циклические компоненты.

Пользуясь подходами выделения трендовых компонент ВР, используем цифровую фильтрацию:
для текущего обучающего примера и нескольких предыдущих примеров (текущую и несколько
предыдущих итераций), количество которых определяет интервал сглаживания.
Обладая этой информации, можно вычислить скользящую среднюю (или экспоненциальную 
скользящую среднюю) и реализовать подавление шумовой компоненты, выделив 
трендовые составляющие.

Таким образом, \textit{комбинированный режим обучения} предполагает учёт текущего
обучающего примера и нескольких предыдущих, что обеспечивает подавление шумовой 
составляющей и циклической компоненты.




\subsubsection{Алгоритм обучения перцептронного нейрона}

Прежде чем переходить к алгоритму обучения многослойного перцептрона, рассмотрим
синтез алгоритмов обучения перцептронного нейрона --- основного структурного
элемента многослойного перцептрона.

\begin{figure}[htbp]
    \centering
    \includegraphics[height=7cm]{hyperflat_6_1.jpeg}
    \caption{Алгоритм обучения перцептронного нейрона}
    \label{hyperflat_6_1}
\end{figure}

Рассмотрим подробнее задачу \textit{дихотомии} (разделение обучающих примеров 
на 2 класса). Имеется метка $+1$ и метка $-1$ принадлежности обучающих примеров 
к 2 альтернативным классам. Рассмотрим синтез алгоритма обучения перцептронного 
нейрона в рамках задачи дихотомии. Реализуется принцип обучения с поощрением, т.е.
для настройки параметров перцептронного нейрона (биас и синаптические веса) 
применяются обучающие пары (представлены в \ref{table:learn_pairs}): обучающие примеры
$\vec{x}$ на входе перцептронного нейрона и желаемое указание (или метка класса) $d$,
поскольку перцептронный нейрон решает задачу \textit{дихотомии} .

\begin{table}[htbp]
    \centering
    \begin{tabular}{c | c}
        $\vec{x}$ --- Обучающие примеры на входе & $d$ --- желаемое указание или метка класса \\\hline
        $\vec{X}[1]$                             & $+1$ \\\hline
        $\vec{X}[2]$                             & $-1$ \\\hline
        $\vdots$                                 & $\vdots$ \\\hline
        $\vec{X}[N]$                             & $+1$ \\\hline
        
    \end{tabular}
    \caption{Обучающие пары}
    \label{table:learn_pairs}
\end{table}

Необходимо в пространстве признаков сформировать модель линейной дискриминантной
границы для того, чтобы реализовать классификацию. Как было сказано выше, существуют
2 случая: линейно разделимых и линейно неразделимых обучающих примеров.
Случай линейно разделимых обучающих примеров достаточно редко встречается
на практике, поэтому для снижения количества неизбежных ошибочных классификаций
для линейно неразделимых векторов образов была придумана \textit{система опорных векторов}.

Рассмотрим сначала простейший случай линейно разделимых векторов образов. Для этого 
понадобится математическая модель перцептронного нейрона:

\begin{equation}
    y = \varphi(\vec{w}^T \cdot \vec{x}),
\end{equation}

\noindent
причём в случае задач дихотомии функция активации $\varphi$ анализирует знак сигнала 
на выходе сумматора нейрона (линейной дискриминантной функции) и принимает вид знаковой
функции (\glqq ступенька\grqq): $\varphi(x)=-1$ для $x<0$ и $\varphi(x)=-1$ для 
$x\geqslant0$. Геометрически представляет собой гиперплоскость.

Таким образом, задачу дихотомии удобно сформулировать в терминах решения системы линейных
неравенств. С этой целью для каждой обучающей пары выпишем соответствующее неравенство:

\begin{equation}
    \begin{cases}
        \vec{w}^T \cdot \vec{X}[1] > 0 \\
        \vec{w}^T \cdot \vec{X}[2] < 0 \\
        \vdots \\
        \vec{w}^T \cdot \vec{X}[N] > 0 \\
    \end{cases}
\end{equation}

Стандартизуем систему линейных неравенств --- приведём все неравенства к знаку $<$. 
Для этого откорректируем все обучающие примеры для тех пар, которые обладают меткой
$+1$ путём домножения их на $-1$. Получим:

\begin{equation}
    \begin{cases}
        \vec{w}^T \cdot \vec{X}[1] < 0 \\
        \vec{w}^T \cdot \vec{X}[2] < 0 \\
        \vdots \\
        \vec{w}^T \cdot \vec{X}[N] < 0 \\
    \end{cases}
    \label{eq:ineq_system}
\end{equation}

Воспользуемся 3 этапами системного подхода Я.З. Цыпкина к синтезу алгоритма обучения
перцептронного нейрона:
\begin{enumerate}
    \item Сформулировать цель обучения;
    \item Найти оценки вектора градиента функции стоимости;
    \item Выписать алгоритм градиентного поиска в $C$-пространстве параметров системы
    (состоит из биаса $w_0$ и синаптических весов $w_i$).
\end{enumerate}




\paragraph{Формулирование цели обучения}

Выберем подходящую модель функции стоимости.

\begin{myquote}
    \textit{Ссылка на книгу Ту, Гонсалес --- Принципы распознавания образов.}
\end{myquote}

В качестве цели обучения выберем среднее арифметическое линейной дискриминантной 
функции и её модуля:

\begin{equation}
    Q(\vec{x}, \vec{w}) = \dfrac{1}{2} \{ \vec{w}^T \cdot \vec{x} + \lvert \vec{w}^T \cdot \vec{x}  \rvert \}
    \label{eq:weight_func_simple}
\end{equation}

Для понимания смысла выбора модели проанализируем 2 случая:
\begin{enumerate}
    \item Неудачный выбор параметров перцептронного нейрона;
    \item Удачный выбор параметров модели.
\end{enumerate}

При неудачном выборе параметров перцептронного нейрона знак неравенства 
из \ref{eq:ineq_system} становится $>0$:

\begin{equation}
    \vec{w}^T \cdot \vec{x} >0 \Rightarrow Q = \vec{w}^T \cdot \vec{x} \sim \dfrac{\vec{w}^T \cdot \vec{x}}{\| \vec{x} \|}
\end{equation}

Т.е., для положительных значений линейной дискриминантной функции потери будут
возрастать линейно --- неудачный выбор будет \glqq наказан\grqq.

В случае удачного выбора параметров перцептронного нейрона:

\begin{equation}
    \vec{w}^T \vec{x} >0 \Rightarrow Q \equiv 0
\end{equation}

Это позволит реализовать 2 режима: \textit{принцип подкрепления} (при удачном
выборе параметров перцептронного нейрона) и \textit{принцип наказания} 
(при неудачном выборе параметров перцептронного нейрона).

В данном случае важно рассматривать выражения не в $x$-пространстве, 
а в $w$-пространстве: при попадании в область неудачных выборов в $w$-пространстве,
необходимо перейти из неё в область удачных выборов. Чем больше расстояние от текущей
точки в $w$-пространстве от отрицательной области, тем сильнее \glqq наказание\grqq.

До этого \glqq числами\grqq являлись параметры перцептронного нейрона $w_i$, а 
\glqq буквами\grqq --- обучающие признаки $x_i$. В $w$-пространстве всё наоборот,
поскольку мы обладаем набором обучающих примеров и $w_i$ --- \glqq буквы\grqq
(аргументы, решение системы линейных неравенств), а $x_i$ --- \glqq числа\grqq.





\paragraph{Получение оценки вектора градиента}

Выпишем в явном виде скалярное произведение $\vec{w}^T \vec{x}$:

\begin{equation}
    \vec{w}^T \vec{x} = w_0 + w_1 \cdot x_1 + \dots + w_n \cdot x_n
\end{equation}

Рассмотрим частные производные этого выражения по компонентам вектора $\vec{w}$:

\begin{align*}
    \dfrac{\partial \left( \vec{w}^T \vec{x} \right)}{\partial w_0} = 1 \\
    \dfrac{\partial \left( \vec{w}^T \vec{x} \right)}{\partial w_1} = x_1 \\
    \vdots \\
    \dfrac{\partial \left( \vec{w}^T \vec{x} \right)}{\partial w_n} = x_n
\end{align*}

Получим, что градиент произведения $\vec{w}^T \vec{x}$ по параметрам перцептронного
нейрона --- это обучающий пример $\vec{x}$:

\begin{equation}
    \nabla_{\vec{W}} \{\vec{w}^T \vec{x} \} = \vec{x}
\end{equation}

При дифференцировании модуля $\lvert x \rvert$ получим:

\begin{equation}
    \dfrac{d\lvert x \rvert}{dx} =
    \begin{cases}
        1, \quad x>0 \\
        -1, \quad x<0
    \end{cases}
    \Rightarrow \dfrac{d\lvert x \rvert}{dx} = \mathrm{sign} (x)
\end{equation}

То есть:

\begin{equation}
    \dfrac{\partial \lvert \vec{w}^T \vec{x} \rvert}{\partial w_i} = x_i \cdot \mathrm{sign} (w_i \cdot x_i)
    \Rightarrow \nabla_{\vec{W}} \{\lvert \vec{w}^T \vec{x} \rvert\} = \vec{x} \cdot \mathrm{sign} \cdot (\vec{w}^T \vec{x})
\end{equation}

Итого получим градиент функции стоимости \ref{eq:weight_func_simple}:

\begin{equation}
    \nabla_{\vec{W}} \{Q\} = \nabla_{\vec{W}} \left[\dfrac{1}{2} \{ \vec{w}^T \cdot \vec{x} + 
    \lvert \vec{w}^T \cdot \vec{x}  \rvert \} \right] 
    = \dfrac{1}{2}  \nabla_{\vec{W}} \left[ \vec{w}^T \vec{x} \right] + 
    \nabla_{\vec{W}} \left[ \lvert \vec{w}^T \cdot \vec{x}  \rvert \right]
    = \dfrac{1}{2} \left(\vec{x} + \vec{x} \cdot \mathrm{sign} (\vec{w}^T \cdot \vec{x})\right)
\end{equation}

Введём обозначение:

\begin{equation}
    \delta (\vec{x}, \vec{w}) = \dfrac{1}{2} \left( 1 + \mathrm{sign} (\vec{w}^T \cdot \vec{x}) \right)
\end{equation}

Заметим также, что:

\begin{equation}
    \delta (\vec{x}, \vec{w}) =
    \begin{cases}
        0, \quad \vec{w}^T \cdot \vec{x} < 0 \quad \textrm{--- удачный выбор параметров перцептронного нейрона}\\
        1, \quad \vec{w}^T \cdot \vec{x} > 0 \quad \textrm{--- неудачный выбор параметров}
    \end{cases}
\end{equation}

Содержательный смысл функции $\delta (\vec{x}, \vec{w})$ --- счётчик ошибок,
накапливающий количество ошибок при неверном выборе параметров перцептронного нейрона.





\paragraph{Алгоритм градиентного поиска}

Выпишем для режима последовательного обучения:

\begin{equation}
    \vec{w}[i] = \vec{w}[i-1] - \delta (\vec{X}[k], \vec{w}[i-1]) \cdot \Gamma[i] \cdot \vec{X}[k]
\end{equation}

Если $\delta (\vec{X}[k], \vec{w}[i-1]) = 0$, то параметры на предыдущей итерации были
выбраны удачно и ничего менять не надо --- \textit{фаза подкрепления}, т.е.
$\vec{w}[i] = \vec{w}[i-1]$, коррекция отсутствует.

Если для вновь поступившего обучающего примера оценка является неудачной, т.е
$\delta (\vec{X}[k], \vec{w}[i-1]) = 0$, то необходимо изменить параметры нейрона ---
\textit{фаза наказания}, осуществляется движение в направлении антиградиента так, чтобы
попасть в отрицательную зону.

В $w$-пространстве граничная гиперплоскость, соответствующая первому неравенству 
из \ref{eq:ineq_system}, делящая пространство на случай удачного и неудачного выбора,
проходит через начало координат, поскольку при $\forall w_i = 0$ 
$\vec{w}^T \cdot \vec{X}[0] = 0$. Поворот гиперплоскости (управляющие косинусы ей нормали)
определяются компонентами обучающего примера: 

\begin{equation*}
    \dfrac{\vec{X}[i]}{\|\vec{X}[i]\|}
\end{equation*}

Вся совокупность граничных гиперплоскостей для всех обучающих примеров проходят через 
начало координат, но ориентированы различным образом (см. правый нижний угол 
\ref{hyperflat_6_1}, синий --- гиперплоскость $1$-го обучающего примера, зелёный ---
--- гиперплоскость $2$-го обучающего примера, красный --- гиперплоскость $N$-го 
обучающего примера).

В случае линейно разделимых векторов образов эти плоскости (\glqq нерегулярно\grqq) 
будут расположены более-менее регулярно, а в идеальном случае --- образуют 
многогранную поверхность в виде разрезанного гиперконуса (гиперпирамиды), 
которая делит $w$-пространство на 2 зоны (положительных и отрицательных значений 
линейной дискриминантной функции).
В этом случае существует минимум одно решение системы линейных неравенств 
\ref{eq:ineq_system}.

Отталкиваясь от начального предложения, необходимо сформировать посегментную траекторию 
градиентного поиска так, чтобы, даже находясь в положительной зоне рано или поздно,
попасть в отрицательную зону $w$-пространства. 

В случае линейно неразделимых обучающих примеров \glqq фацеты\grqq будут расположены
нерегулярно (хаотически), так, что нельзя будет найти точку в $w$-пространстве, 
удовлетворяющей всем неравенствам \ref{eq:ineq_system}. Как было сказано выше,
эту задачу решает \textit{машина опорных векторов}, обеспечивающая выбор параметров
перцептронного нейрона с минимальным количеством нарушений.

В случае процедуры стохастической аппроксимации Роббенса-Монро шаг поиска выбирают,
отталкиваясь от начального приближения в направлении антиградиента пропорционально
величине $\eta$ --- \textit{параметру скорости обучения}.

\begin{equation}
    \Gamma[i] = \dfrac{\eta}{i} I_{n+1}
\end{equation}

\noindent
где $I_{n+1}$ --- единичная матрица размерности $n+1$, поскольку помимо $n$ синаптических
весов присутствует биас $w_0$.

Уменьшение шага поиска пропорциональное номеру шага обучения гарантирует сходимость метода
как минимум в случае линейно разделимых векторов образов.
Номер текущего обучающего примера $k$ выбирается, как значение целочисленной переменной $i$ 
по модулю $N$ --- остаток от деления нацело номера итерации на количество обучающих 
примеров:

\begin{equation*}
    k = (i)_N
\end{equation*}




\section{Лекция 16.04 (Опоздал на полчаса)}

Алгоритмы обучения перцептронного нейрона в рамках задачи дихотомии
в соответствии с системным подходом реализуют 3 этапа (см. выше )
В пространстве параметров обучающие примеры --- это числа, гиперплоскости,
проходящие через начало координат, пропорционально направляющим косинусам.
Для случая линейно разделимых образов регулярная структура (разрезанная пирамида 
в виде фацетов) делит пространство параметров на + и -. 
В отрицательную часть необходимо стремиться.


Сегментарная траектория поиска в области отрицательных значений. Мы
считаем, что система неравенств имеет решение.
% Фото hyperflat_6 1-7 1. 

% Была на пред. лекции
% \begin{figure}[htbp]
%     \centering
%     \includegraphics[height=7cm]{hyperflat_6_1.jpeg}
%     \caption{hyperflat\_6\_1}
% \end{figure}

Для каждого обучающего примера, фаза наказания:
Х-числа, W-буквы. Параметр скорости - 1 - ортогонально. Параметр скорости 2 -
зеркальное отражение. Обычно берут долю


% ------------------------------------
% В этот момент пришёл
% ------------------------------------

\begin{figure}[H]
    \centering
    \includegraphics[height=8 cm]{hyperflat_7_1.jpeg}
    \caption{Аппроксимация многомерной скалярной функции (hyperflat\_7\_1)}
    \label{hyperflat_7_1}
\end{figure}

\textbf{Геометрическая интерпретация}
Параметр скорости обучения $\eta$ выбирают, как .. 
Переходя от одного к другому обучающему примеру, приближаемся к поверхности разрезанной 
пирамиды.

% Скорее всего, subsubsection
\subsection{Пример с квадратичной функцией потерь}

\begin{figure}[htbp]
    \centering
    \includegraphics[height=7cm]{hyperflat_8_1.jpeg}
    \caption{\dots с квадратичной функцией потерь}
    \label{hyperflat_8_1}
\end{figure}

Фиксируем потери, пропорциональные квадрату расстояния до гиперплоскости обучающего 
примера, --- потери возрастают квадратично. Методика рассмотрена на предыдущем 
(дистанционном) занятии.

\begin{myquote}
    \textit{Вычислить градиент функции потерь на листике}
\end{myquote}

Имея текущий обучающий пример $x_k$ и текущие параметры нейрона $\vec{W}[i-1]$,
..

В W-пространстве нормаль $\vec{u}[k]$ вычисляется как: 

\begin{equation}
    \dfrac{\vec{X}_k}{\| \vec{X}_k \|}
\end{equation}

Положим, что для $k$-го обучающего примера параметры неудачны. В этом случае опускаем перпендикуляр
к гиперплоскости и вычисляем расстояние до неё:

\begin{equation}
    D_W [k] = \dfrac{\lvert \vec{W}^T [i-1] \vec{X}[k] \rvert}{\| \vec{X}[k] \|}
\end{equation}

Долю масштаба определяют компоненты матрицы $\Gamma[i]=\dfrac{\eta}{i} I_{n\times m}$, где $I_{n \times m}$ - единичная матрица.

\begin{myquote}
    \textit{Харман, Математические основы математической вычислительной томографии, глава "РВТ"}
\end{myquote}

\begin{myquote}
    \textit{Также в книге присутствует алгоритм, в котором для гиперплоскости каждого обучающего 
    примера выбирается некая погрешность и гиперплоскость обволакивается полосой
    шириной $\pm \varepsilon$ в связи с присутствием погрешностей в "реальных" примерах.}
\end{myquote}

Для простоты анализа здесь был выбран режим последовательного обучения, однако ранее были обсуждены 
также алгоритмы
\textit{смешанного обучения}.

\begin{myquote}
    \textit{Рекомендовано выписать этот алгоритм для простой и экспоненциальной (задача со звёздочкой) 
    скользящей средней}
\end{myquote}

Здесь рассмотрен случай линейно разделимых разделимых векторов образов, исходя из предположения, что система 
линейных неравенств имеет минимум одно решение.
Иначе будет минимум одна зона в $W$-пространстве, характеризуемая количеством ошибочных классификаций 
и необходим алгоритм, строящий \textit{оптимальную гиперплоскость}.

Для \textit{оптимальной гиперплоскости} количество неизбежных ошибочных классификаций минимально. 
Такой метод был реализован Владимиров Вапником в \textit{методе опорных векторов}.

Булавский (НГУ) предложил симплекс-метод для решения несовместных систем линейных неравенств --- 
поиска компромиссного решения. 
Метод применим для случая линейно неразделимых векторов образов и является альтернативой методу 
опорных векторов. 
Метод не получил широкого распространения, имеется только препринт.


\begin{myquote}
    \textit{Препринт есть у ЛЛВ}
\end{myquote}

\subsection{Аппроксимация многомерной скалярной функции}

\begin{figure}[htbp]
    \centering
    \includegraphics[height=7cm]{hyperflat_9_1.jpeg}
    \caption{Аппроксимация многомерной скалярной функции}
    \label{hyperflat_9_1}
\end{figure}

Рассмотрим альтернативную дихотомии задачу - аппроксимацию многомерной скалярной функции,  т.е.
синтез закономерности, скрытой в данных, с помощью многослойного перцептрона.
В данном случае стоит воспринимать перцептрон как устройство воспроизведения математической модели.

\begin{table}[H]
    \centering
    \begin{tabular}{| c | c | c | c |}
        \hline
        $\vec{x}$ & $d$ & $y$ & $e$ \\
        \hline
        $\vec{X}[1]$ & $d[1]$ & $y[1]$ & $e[1]$ \\
        \hline
        $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ \\
        \hline
        $\vec{X}[N]$ & $d[N]$ & $y[N]$ & $e[N]$ \\
        \hline
    \end{tabular}
    \label{table:scalar-func-table}
    \caption{Табличная форма задания многомерной скалярной функции}
\end{table}

Имеется табличная форма задания многомерной скалярной функции (\ref{table:scalar-func-table}), 
набор обучающих примеров в виде совокупности факторов (входных аргументов) $\vec{x}[i]$, $d$ ---
желаемое выходной значение скрытой закономерности, $y = \varphi (\vec{W}^T \vec{x})$ ---
фактическое значение (реакция) перцептрона и ошибка $e = d - y$.

Необходимо синтезировать математическую модель с помощью перцептронного нейрона. 
$\vec{x}$ --- обобщенный вектор образов с $+1$ в первой позиции, $\vec{W}$ ---
обобщенный вектор синаптических весов с биасом в первой позиции.

Будем выполнять задачу согласно этапам системного подхода.



\subsubsection{Выбор модели фунции стоимости}

Выберем квадратичную функцию ошибок:

\begin{equation}
    Q(\vec{x}, \vec{W}) = e^2(\vec{x}, \vec{W})
\end{equation}

Тогда средние потери будут равны:
    
\begin{equation}
    E(\vec{W}) = \sum_{k=1}^{T} e^2 (\vec{X}[k], \vec{W})
    \label{eq:sum-err}
\end{equation}



\subsubsection{Поиск градиента функции ошибок}

Необходимо найти в $W$-пространстве такую точку, которая минимизировала бы суммарную 
энергию ошибок $E(\vec{W})$ \ref{eq:sum-err}.

\begin{equation}
    \nabla_{\vec{W}} \{ E(\vec{W}) \} = 2 \sum_{k=1}^{N} e (\vec{X}[k], \vec{W}) \cdot (-1)
    \cdot \varphi ' (\vec{W}^T \cdot \vec{X}[k]) \vec{X}[k]
\end{equation}

В первую очередь интересно произведение первой производной функции активации и функции ошибки, 
которую обозначим $\delta(\vec{x}, \vec{W})$:

\begin{equation}
    \delta(\vec{x}, \vec{W}) = \varphi ' (\vec{W}^{T} \cdot \vec{x}) \cdot e(\vec{x}, \vec{W})
\end{equation}
\noindent
и будем называть \textit{локальным градиентом}. 
Он введён, поскольку при выполнении поиска выгоднее находиться в области ненулевых значений
функции активации (иначе итерация "пропадает").



\subsubsection{Применение алгоритма градиентного поиска}

Распишем алгоритм градиентного поиска (пакетный режим):

\begin{equation}
    \vec{W}[i] = \vec{W}[i-1] + \sum_{k=1}^{N} \delta(\vec{X}[k], \vec{W}[i-1])\cdot \vec{\Gamma[i]} \cdot \vec{X}[k]
\end{equation}

\begin{myquote}
    Рекомендовано выписывать алгоритм слева направо - скаляр, матрица, вектор.
\end{myquote}

Для усиления шумового эффекта игнорируется усреднение по всем примерам (удаление знака суммы) и выполняется 
пересчёт после каждого нового значения - последовательное обучение:

\begin{equation}
    \vec{W}[i] = \vec{W}[i-1] + \delta(\vec{X}[k], \vec{W}[i-1])\cdot \vec{\Gamma[i]} \cdot \vec{X}[k]
    \label{eq:delta-rule}
\end{equation}

Режим последовательного обучения реализует \textit{оптимизирующий алгоритм Уидроу-Хоффа} \ref{eq:delta-rule}, 
иначе называемый \textit{дельта-правилом}.

При введении сглаживания с помощью модели EMA получим \textit{обобщённое дельта-правило}.




\subsection{Алгоритм обратного распространения ошибок обучения многослойного перцептрона}

\begin{myquote}
    \textit{Lec\_neuro\_08.docx}
\end{myquote}

Основным параметром алгоритма обучения Уидроу-Хоффа является ошибка реакции, которая 
недоступна при обучении нейронов скрытых слоёв.
Эту проблему решает алгоритм обратного распространения ошибок.

Упростим схему индексации нейронов (см. \ref{hyperflat_10_1}):

\begin{figure}[htbp]
    \centering
    \includegraphics[width=7cm]{hyperflat_10_1.jpeg}
    \caption{Новая схема индексации нейронов}
    \label{hyperflat_10_1}
\end{figure}

Для этого примем следующие соглашения:
\begin{enumerate}
    \item Для обозначения 1-го скрытого слоя используем символ $i$, нейроны 2-го скрытого слоя 
    обозначим символами $j$, выходные нейроны обозначим символами $k$, $l$ - символ линейных 
    нейронов 0-го слоя.
    \item Связь между нейронами младшего и старшего слоя (синаптический вес) --- $W{ji}$, 
    $j$ --- символ нейрона старшего слоя, $i$ --- символ нейрона младшего слоя, 
    для биаса второй индекс $0$.
    \item Во входном слое $m_0$ нейронов (функциональных входов), во 2-м слое 
    $m_1$ нейронов, в 3-м слое $m_2$ нейронов.
\end{enumerate}

Алгоритм обратного распространения содержит 2 вычислительных этапа
\begin{enumerate}
    \item \textbf{Этап прямого распространения.} В соответствии с математической моделью многослойного 
    перцептрона можем распространить все сигналы в прямом направлении --- посчитать фактические 
    реакции нейронов скрытых слоёв и выходные реакции нейронов. 
    
    В финале этого этапа обладаем выходными реакциями нейронов, на основе которых можно 
    вычислить сигналы ошибок и локальные градиенты, а значит, применить дельта-правило 
    и скорректировать параметры нейронов выходного слоя.
    \item \textbf{Этап обратного распространения.} 
    На этом этапе распространяются сигналы ошибок для нейронов скрытых слоёв.
\end{enumerate}



\subsubsection{Этап прямого распространения}

Этап начинается с расчёта фактических реакций на выходе нейронов 1-го скрытого слоя. 

Рассчитаем сигнал на выходе сумматора текущего $i$-го нейрона на выходе 1-го скрытого слоя, 
на вход которого  поступает сигнал смещения \glqq +1\grqq, взвешиваемый биасом, и входные признаки 
$x_m0$, взвешиваемые синаптическим весом $w_{im_0}$.

На выходе сумматоров получим:

\begin{equation}
    v_i (n) = \sum_{L=0}^{m_{0}} w_{il}(n) x(n)
\end{equation}

\noindent
$n$ - номер итерации.

Подвергаем его нелинейному преобразованию и получаем реакции на выходе нейронов 1-го скрытого слоя:

\begin{equation}
    y_i(n) = \varphi (v_i(n)), \quad i=\overline{1,m_1}
\end{equation}

Посчитаем сигналы на выходе сумматоров нейронов 2-го скрытого слоя:

\begin{equation}
    v_j (n) = \sum_{i=0}^{m_{1}} w_{ji}(n) y_i(n)
\end{equation}

На выходе нейронов 2-го скрытого слоя после нелинейного преобразования:

\begin{equation}
    y_j(n) = \varphi (v_j(n)), \quad j=\overline{1,m_2}
\end{equation}

Аналогично на выходе сумматоров нейронов 3-го скрытого слоя:

\begin{equation}
    v_k (n) = \sum_{j=0}^{m_{2}} w_{kj}(n) y_j(n)
\end{equation}

На выходе нейронов 3-го скрытого слоя после нелинейного преобразования:

\begin{equation}
    y_k(n) = \varphi (v_k(n)), \quad k=\overline{1,m_3}
\end{equation}

Зная фактические реакции выходных нейронов, вычислим набор ошибок:

\begin{equation}
    e_{k}(n) = d_k(n) - y_k(n)
\end{equation}

Вычисляем величину локального градиента выходных нейронов:

\begin{equation}
    \delta_k(n) = \varphi^{\prime}(v_k(n))\cdot e_k(n)
\end{equation}

Алгоритм коррекции $k$-го выходного нейрона:

\begin{equation}
    w_{kj}(n) = w_{kj}(n-1) + \dfrac{\eta}{N} \cdot \delta_{k}(n) \cdot y_j(n), k=\overline{1,m_3}
\end{equation}

Этап прямого распространения закончен.




\subsubsection{Этап обратного распространения}

В соответствии с методом потоковых графов, разработанным Станиславом Осовским и описанным в книге
\glqq Нейронные сети для обработки информации\grqq, любую сеть можно представить в виде набора графов,
 имеющих узлы (сигналы) и рёбра (направления распространения сигналов и коэффициенты усиления).
Если рёбра сходятся в одном узле, то это означает суммирование соответствующих сигналов.

\begin{figure}[H]
    \centering
    \includegraphics[height=5cm]{lec_neuro_08_4_3.png}
    \caption{Граф передачи сигнала в пределах $j$-го нейрона}
    \label{lec_neuro_08_4_3}
\end{figure}

Для нейронов выходного слоя имеем сигналы ошибки $e_1(n),\dots,e_k(n),\dots,e_{m_3}$, которые 
умножаются на вычисленные значения функции активации $\varphi^{\prime}(v_k(n))$ и получаем значения 
локальных градиентов выходных нейронов $\delta_k(n)$, а затем используем алгоритм обратного 
распространения ошибок.

\begin{figure}[htbp]
    \centering
    \includegraphics[height=5cm]{lec_neuro_08_4_5.png}
    \caption{Направление двух потоков сигналов в многослойном перцептроне}
    \label{lec_neuro_08_4_5}
\end{figure}

Основной результат заключается в правиле вычисления ошибок для нейронов младшего слоя. 
Показано, что сигнал ошибки может быть вычислен в виде взвешенной суммы локальных градиентов
нейронов n-го слоя:

\begin{equation}
    e_j(n) = \sum_{k=1}^{m_3} w_{kj}(n) \delta_k (n)
\end{equation}

\begin{myquote}
    \textit{Возможно, суммирование должно быть от 0.}
\end{myquote}

Вычислив ошибку для нейронов второго слоя, вычислим для него локальный градиент, т.е. 
распространим ошибку на шаг назад:

\begin{equation}
    \delta_j(n) = e_j(n) \cdot \varphi^{\prime} (v_j(n))
\end{equation}

Значит, возможно произвести \glqq редактирование\grqq синаптических весов нейронов второго слоя. Т.е.:

\begin{equation}
    w_{ji}(n) = w_{ji}(n-1) + \dfrac{\eta}{N} \cdot \delta_j \cdot y_i(n)
\end{equation}

Для нейронов первого скрытого слоя:

\begin{equation}
    e_i(n) = \sum_{j=1}^{m_2} w_{ji}(n) \delta_j
\end{equation}

\begin{myquote}
    \textit{Возможно, суммирование должно быть от 0.}
\end{myquote}

\begin{equation}
    \delta_i(n) = e_i(n) \cdot \varphi^{\prime} (v_i(n))
\end{equation}

Для входного слоя получим:

\begin{equation}
    w_{il}(n) = w_{il}(n-1) + \dfrac{\eta}{N} \cdot \delta_i \cdot x_l
\end{equation}

Произошло распространение ошибок и локального градиента в обратном направлении, что
позволило применить обычное дельта-правило.



\section{Новая}
\subsection{Практические рекомендации по улучшению сходимости алгоритма обратного распространения ошибок}


\end{document}